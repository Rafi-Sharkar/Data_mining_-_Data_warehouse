{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "KMeans Clustering"
      ],
      "metadata": {
        "id": "CsvLrbDMV97W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "import json\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "kH5Got1dWAno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fuFCYG9Z1PG",
        "outputId": "5ff60b08-8b3b-477a-f2e0-38f2f54eac62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the pseudocode tolad Load data from file and save in the numpy matrix.\n",
        "You can use panda to read the dataset in to numpy matrix. data matrix will have data points. First column is point index. Rest of the columns have features.  ClassLabel has the labels."
      ],
      "metadata": {
        "id": "QMeWajTXWF0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load(file_name):\n",
        "    # data(2D list or list of list): [[ . . .4 dimensions . . .], [..., ...], ...]\n",
        "    x =  pd.read_csv(file_name).to_numpy()\n",
        "    data = x[:,:-1]\n",
        "    # classLabel = x[:,-1]\n",
        "    return data   #classLabel contains class label"
      ],
      "metadata": {
        "id": "RkLX9kQDWMLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "simple centroid initialization function"
      ],
      "metadata": {
        "id": "RvgJK_f_WOlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_centroids_simple(data, dimension, k):\n",
        "    #centroids: [[centroid0:  3 dimensions, , , ]; [centroid1: 3 dimensions ] ... ..]\n",
        "    centroids = np.array([[0 for _ in range(dimension)] for _ in range(k)])\n",
        "    #TO DO\n",
        "    np.random.shuffle(data)\n",
        "    rows = data[:k, :]\n",
        "    centroids = rows\n",
        "    #Write your code to return initialized centroids by randomly assiging them to K points\n",
        "    return centroids"
      ],
      "metadata": {
        "id": "xZm_BPcEWTlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate eucledian distance"
      ],
      "metadata": {
        "id": "J3vAsctEWwYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_euclidean_distance(p1, p2):\n",
        "    distance = -1.0\n",
        "    distance = np.linalg.norm(p1 - p2)\n",
        "    return distance"
      ],
      "metadata": {
        "id": "VfZobkk-W2FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KMeans Function\n"
      ],
      "metadata": {
        "id": "YvA2jiqiXBvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kmeans(data, dimension, k):\n",
        "    N = np.size(data, 0)\n",
        "    #centroids: [[centroid0:  , , ,3 dimensions, , , ]; [centroid1: , , ,3 dimensions, , , ] ... ..]\n",
        "    centroids = initialize_centroids_simple(data, dimension, k)\n",
        "    #cluster_affiliation: cluster_affiliation = [clusternumber, clutsernumber, ..., ..., ..., ...]\n",
        "    flag = 1\n",
        "    #initialize the cluster affiliations. Initially assign -1\n",
        "    cluster_affiliation = np.array([-1 for _ in range(0, N)])\n",
        "    while flag:\n",
        "       for i, point in enumerate(data):\n",
        "            min_distance = float('inf')\n",
        "            min_distance_index = None\n",
        "\n",
        "            #find closest centroids for each data points\n",
        "            for cluster_index, centroid in enumerate(centroids): #use numpy equivalent code\n",
        "                distance = get_euclidean_distance(centroid, point)\n",
        "                if distance < min_distance:\n",
        "                    min_distance = distance\n",
        "                    min_distance_index = cluster_index\n",
        "\n",
        "            #record or update cluster for each data points\n",
        "            if cluster_affiliation[i] != min_distance_index:\n",
        "               cluster_affiliation[i] = min_distance_index\n",
        "\n",
        "       #recompute centroids\n",
        "       new_centroids = np.array([[0 for _ in range(dimension)] for _ in range(k)]) # new centroids initialized with 0\n",
        "       cluster_point_count = np.array([0 for _ in range(k)]) #keep number of points for each cluster. You should use\n",
        "       #cluster_affiliation  to calculate it\n",
        "       #TO DO\n",
        "       #write your code to count each cluster pointcount and store them in clutser_point_count structure\n",
        "       cluster_array = [[] for _ in range(k)]\n",
        "       for i in range(N):   # make saparation by diff cluster\n",
        "         cluster_point_count[cluster_affiliation[i]] += 1\n",
        "         cluster_array[cluster_affiliation[i]].append(data[i])\n",
        "\n",
        "       #recompute centroids using the count\n",
        "       for i in range(len(cluster_array)):    # update it's centroids\n",
        "         new_centroids[i] = np.divide(np.sum(cluster_array[i], axis = 0),cluster_point_count[i])\n",
        "\n",
        "       for i in range(k):\n",
        "         if get_euclidean_distance(new_centroids[i],centroids[i])<0.00005:\n",
        "           flag  = False\n",
        "\n",
        "       centroids = new_centroids\n",
        "\n",
        "    #TO DO\n",
        "    #Terminate the while loop based on termination criteria. Write your code to turn flag = false\n",
        "    return (centroids, cluster_affiliation)\n"
      ],
      "metadata": {
        "id": "G-5U2bt-XI8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Driver funtion/Main Function"
      ],
      "metadata": {
        "id": "XduHk-N0XKQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "\n",
        "  K = 4\n",
        "  data = load('/content/drive/MyDrive/data set/wheetseeds.csv')\n",
        "  dimension = np.size(data, 1)\n",
        "\n",
        "  centroids, cluster_affiliation = kmeans(data, dimension, K)\n",
        "  # print('Duration: %s' % (time.time() - start))\n",
        "\n",
        "  print(centroids, cluster_affiliation)\n",
        "\n",
        "\n",
        "\n",
        "main()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EdutF8_91Wq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a533f4-db17-432e-cddb-44147490edac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[18 16  0  6  3  3  5]\n",
            " [14 14  0  5  3  2  5]\n",
            " [12 13  0  5  2  4  5]\n",
            " [11 13  0  5  2  5  5]] [0 1 2 3 1 0 0 0 0 2 3 2 1 0 0 0 1 3 2 2 2 1 0 2 1 0 1 0 1 1 0 3 2 3 0 0 2\n",
            " 2 2 0 1 2 3 2 0 1 0 2 0 3 0 0 2 0 1 1 2 2 0 3 2 2 0 1 1 2 1 0 3 1 1 0 3 3\n",
            " 1 0 1 1 0 0 2 2 0 1 1 3 0 2 2 0 0 2 1 0 0 1 2 2 0 2 0 0 0 1 1 2 3 1 0 1 1\n",
            " 1 2 2 0 2 3 2 2 1 1 2 1 1 1 3 2 2 1 1 1 0 2 1 0 0 2 2 0 2 1 0 0 0 2 2 1 3\n",
            " 1 3 0 0 2 3 1 0 0 0 0 0 2 1 1 0 1 3 2 1 2 0 1 1 0 0 0 1 0 0 2 1 2 0 1 2 0\n",
            " 1 2 1 1 0 3 1 0 1 0 0 1 0 0 0 0 1 1 2 0 2 2 0 1 3]\n"
          ]
        }
      ]
    }
  ]
}